# express.js application configuration
SERVER_PORT=8090
ROOT_ADDRESS=http://localhost:8090
# the maximum size in megabytes of request bodies sent to DeepLynx
# requests with payloads over this limit will return a 413 note that
# this does not apply to file size, only raw body size
MAX_REQUEST_BODY_SIZE=50

# there are various processes that look for other compiled typescript files
PROJECT_DIR=./dist

# whether or not to use the server instance to also manage the jobs
RUN_JOBS=true

# comma separated CORs origins, defaults to *
CORS_ORIGIN=

# valid options are blank (defaults to memory), memory, or redis
CACHE_PROVIDER=memory
# default time in seconds
CACHE_DEFAULT_TTL=21600
# redis connection string - e.g redis://user:password@redis-service.com:6379/
CACHE_REDIS_CONNECTION_STRING=
# redis graph expiry timer in seconds
REDIS_GRAPH_TTL=3600

CACHE_GRAPHQL=true

# this controls the import id caching on staging data emission and processing, only change
# if you know what you're doing - in seconds
INITIAL_IMPORT_CACHE_TTL=21600
IMPORT_CACHE_TTL=30

# email specific variables, controls the reset password/email validation/ links etc.
# the URLs should refer to your UI implementation's reset password, email validation, and container invite pages
EMAIL_ADDRESS=do+not+reply@deeplynx.org
EMAIL_ENABLED=false
EMAIL_VALIDATION_ENFORCED=false
CONTAINER_INVITE_URL=http://localhost:8080/container-invite

# debug,info,warn,error,silent
LOG_LEVEL=debug
LOG_JOBS=false

# should be in the format postgresql://user:password@hostname:port/database_name
# :port is optional and if included will usually be :5432
CORE_DB_CONNECTION_STRING=postgresql://postgres:deeplynxcore@localhost/deep_lynx
TIMESCALEDB_ENABLED=false

# this must be an absolute path to a RSA private key - if one is not provided it will be generated and saved for you at
# the project root
ENCRYPTION_KEY_PATH=
# this must be an absolute path to a RSA public key - if one is not provided it will be generated and saved for you at
# the project root in most cases. If you have an already existing private key, generate a public key from it
ENCRYPTION_PUBLIC_KEY_PATH=

# plaintext secret used to generate secure session markers
SESSION_SECRET=

# controls which file storage method to use, possible values are azure_blob, minio, and filesystem
# note that minio can also be used to communicate with AWS S3 services
FILE_STORAGE_METHOD=filesystem
# must end with a directory character (e.g. "/")
FILESYSTEM_STORAGE_DIRECTORY=./../storage/
# setting the default here as the connection string for Azurite. Azurite is a local emulator for mocking up
# azure storage and can be used for local testing and development. This connection string does not expose any
# sensitive credentials as it is the default and can be found in the Azurite documentation linked below:
# https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azurite?tabs=visual-studio%2Cblob-storage#well-known-storage-account-and-key
AZURE_BLOB_CONNECTION_STRING=
AZURE_BLOB_CONTAINER_NAME=deep-lynx

# MINIO can also be used to communicate with S3 Storage
MINIO_ENDPOINT=
MINIO_PORT=
MINIO_SSL=false
MINIO_ACCESS_KEY=
MINIO_SECRET_KEY=

# determines wheter or not this instance of DL is the main instance or a supporting node in a cluster
IS_NODE=false

# controls how many records a data source can insert into the database in a single transaction
DATA_SOURCE_RECEIVE_BUFFER=1000
# controls how often the data source job is ran
DATA_SOURCE_PROCESSING_INTERVAL=1m
# controls how many data sources can run their processing loops at once
DATA_SOURCE_PROCESSING_CONCURRENCY=4
DATA_SOURCE_PROCESSING_BATCH_SIZE=1000

# specify the queue name for Data Targets, default = 'data_targets'
DATA_TARGETS_QUEUE_NAME=

# controls how often the export data job is ran
EXPORT_INTERVAL=10m
# controls how many exports can occur at once
EXPORT_DATA_CONCURRENCY=4

# controls which queue system to use, possible values are database, rabbitmq and azure_service_bus
QUEUE_SYSTEM=database
# RabbitMQ connection string
RABBITMQ_URL=
# Azure Service Bus connection string
AZURE_SERVICE_BUS_CONNECTION_STRING=

EDGE_INSERTION_BACKOFF_MULTIPLIER=5
EDGE_INSERTION_MAX_RETRY=10

# controls whether or not DeepLynx should emit data events
EMIT_EVENTS=true

# whether or not to create a superuser on initial boot, along with the values
# for its email and password - password will be encrypted prior to storage
INITIAL_SUPERUSER=true
SUPERUSER_EMAIL=admin@admin.com
SUPERUSER_PASSWORD=admin

# these settings are needed for the admin web gui build that takes place as part of DeepLynx
VUE_APP_BUNDLED_BUILD=true
VUE_APP_TIME_SERIES_ENABLED=false
VUE_APP_DEEP_LYNX_API_URL=http://localhost:8090
VUE_APP_DEEP_LYNX_API_AUTH_METHOD=token
VUE_APP_APP_URL=http://localhost:8090/#
# if you are bundling the web app, you must set a unique ID in order for DeepLynx to recognize the internal admin web app
# when it attempts to authenticate against the program, we recommend at least 15 random alphanumeric characters, and not
# a recognizable name - at no point will a user see this information
VUE_APP_DEEP_LYNX_APP_ID=root

# while you can set basic, note that the session functionality will not work. Leaving this blank
# will remove all authentication methods
# possible values: token, basic, (leave blank for no auth)
AUTH_STRATEGY=token

BASIC_USER=
BASIC_PASSWORD=

SAML_ENABLED=false
# SAML 2.0 entry point URL
SAML_ADFS_ENTRY_POINT=
# Application (Client) ID
SAML_ADFS_ISSUER=
# Application callback route, registered with Identity provider beforehand
SAML_ADFS_CALLBACK=
# Self signed certificate private key (.key file)
SAML_ADFS_PRIVATE_CERT_PATH=
# x509 certificate extracted from ADFS metadata file
SAML_ADFS_PUBLIC_CERT_PATH=
# Algorithm used for signing requests (default is sha256)
SAML_ADFS_SIGNATURE_ALGORITHM=

# SAML audience to validate with IDP (defaults to 'false' which causes no validation)
SAML_ADFS_AUDIENCE=

# Additional SAML flags (default is true)
SAML_ADFS_DISABLE_REQUESTED_AUTHN_CONTEXT=

# Additional SAML flags (default is false)
SAML_ADFS_WANT_AUTHN_RESPONSE_SIGNED=
SAML_ADFS_WANT_ASSERTIONS_SIGNED=

SAML_ADFS_CLAIMS_EMAIL=
SAML_ADFS_CLAIMS_NAME=

# SMTP Mail server specific settings
SMTP_USERNAME=
SMTP_PASSWORD=
SMTP_HOST=
SMTP_PORT=25
SMTP_TLS=true

# SMTP OAuth2 settings
SMTP_CLIENT_ID=
SMTP_CLIENT_SECRET=
SMTP_REFRESH_TOKEN=
SMTP_ACCESS_TOKEN=

# RSA Server settings
RSA_URL=
RSA_CLIENT_KEY=
RSA_CLIENT_ID=

# Email for the authorized HPC user to access tasks
HPC_EMAIL=

# Serval URL
SERVAL_URL=